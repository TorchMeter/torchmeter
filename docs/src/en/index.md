---
hide:
    - toc
    - navigation
---

<!-- logo -->
<figure markdown="span">
    ![TorchMeter Banner](assets/banner/banner_black.png#only-light){ .off-glb }
    ![TorchMeter Banner](assets/banner/banner_white.png#only-dark){ .off-glb }
</figure>

<!-- caption -->
<p align="center">
    ğŸš€ <ins>ğ’€ğ’ğ’–ğ’“ ğ‘¨ğ’ğ’-ğ’Šğ’-ğ‘¶ğ’ğ’† ğ‘»ğ’ğ’ğ’ ğ’‡ğ’ğ’“ ğ‘·ğ’šğ’•ğ’ğ’“ğ’„ğ’‰ ğ‘´ğ’ğ’…ğ’†ğ’ ğ‘¨ğ’ğ’‚ğ’ğ’šğ’”ğ’Šğ’”</ins> ğŸš€
</p>

<!-- badge -->
<p align="center">
    <a href="https://pypi.org/project/torchmeter/"><img alt="PyPI-Version" src="https://img.shields.io/pypi/v/torchmeter?logo=pypi&logoColor=%23ffffff&label=PyPI&color=%230C7EBF"></a>
    <a href="https://www.python.org/"><img alt="Python-Badge" src="https://img.shields.io/badge/Python-%3E%3D3.8-white?logo=python&logoColor=%232EA9DF&color=%233776AB"></a>
    <a href="https://pytorch.org/"><img alt="Pytorch-Badge" src="https://img.shields.io/badge/Pytorch-%3E%3D1.7.0-white?logo=pytorch&logoColor=%23EB5F36&color=%23EB5F36"></a>
    <a href="https://github.com/astral-sh/ruff"><img alt="Ruff-Badge" src="https://img.shields.io/badge/Ruff-Lint_%26_Format-white?logo=ruff&color=%238B70BA"></a>
    <a href="https://github.com/TorchMeter/torchmeter/blob/master/LICENSE"><img alt="Static Badge" src="https://img.shields.io/badge/License-AGPL--3.0-green"></a>
</p>

<!-- simple introduction -->

- **Repo**: https://github.com/TorchMeter/torchmeter
- **Intro**: Provides {++comprehensive++} measurement of `Pytorch` model's `Parameters`, `FLOPs/MACs`, `Memory-Cost`, `Inference-Time` and `Throughput` with {++highly customizable++} result display âœ¨

## ğ’œ. ğ»ğ’¾ğ‘”ğ’½ğ“ğ’¾ğ‘”ğ’½ğ“‰ğ“ˆ

??? tip ":material-numeric-1-circle-outline: ğš‰ğšğš›ğš˜-ğ™¸ğš—ğšğš›ğšğšœğš’ğš˜ğš— ğ™¿ğš›ğš˜ğš¡ğš¢"

    - [x] Acts as ^^drop-in^^ decorator {++without++} any changes of the underlying model
    - [x] Seamlessly integrates with `Pytorch` modules while preserving {++full++} compatibility (attributes and methods)

??? tip ":material-numeric-2-circle-outline: ğ™µğšğš•ğš•-ğš‚ğšğšŠğšŒğš” ğ™¼ğš˜ğšğšğš• ğ™°ğš—ğšŠğš•ğš¢ğšğš’ğšŒğšœ"

    Holistic performance analytics across {++5++} dimensions: 

    - [x] {++Parameter Analysis++}
        - Total/trainable parameter quantification
        - Layer-wise parameter distribution analysis
        - Gradient state tracking (requires_grad flags)
    
    - [x] {++Computational Profiling++}
        - FLOPs/MACs precision calculation
        - Operation-wise calculation distribution analysis
        - Dynamic input/output detection (number, type, shape, ...)
    
    - [x] {++Memory Diagnostics++} 
        - Input/output tensor memory awareness
        - Hierarchical memory consumption analysis

    - [x] {++Inference latency & 5. Throughput benchmarking++}
        - Auto warm-up phase execution (eliminates cold-start bias)
        - Device-specific high-precision timing
        - Inference latency  & Throughput Benchmarking

??? tip ":material-numeric-3-circle-outline: ğšğš’ğšŒğš‘ ğš…ğš’ğšœğšğšŠğš•ğš’ğš£ğšŠğšğš’ğš˜ğš—"

    - [x] {++Programmable tabular report++}
        - Dynamic table structure adjustment
        - Style customization and real-time rendering
        - Real-time data analysis in programmable way

    - [x] {++Rich-text hierarchical operation tree++}
        - Style customization and real-time rendering
        - Smart module folding based on structural equivalence detection for intuitive model structure insights

??? tip ":material-numeric-4-circle-outline: ğ™µğš’ğš—ğš-ğ™¶ğš›ğšŠğš’ğš—ğšğš ğ™²ğšğšœğšğš˜ğš–ğš’ğš£ğšŠğšğš’ğš˜ğš—"

    - [x] {++Real-time hot-reload rendering++}: <br> Dynamic adjustment of rendering configuration for operation trees, report tables and their nested components <br>

    - [x] {++Progressive update++}: <br>Namespace assignment + dictionary batch update

??? tip ":material-numeric-5-circle-outline: ğ™²ğš˜ğš—ğšğš’ğš-ğ™³ğš›ğš’ğšŸğšğš— ğšğšğš—ğšğš’ğš–ğš ğ™¼ğšŠğš—ğšŠğšğšğš–ğšğš—ğš"

    - [x] {++Centralized control++}: <br>Singleton-managed global configuration for dynamic behavior adjustment <br>

    - [x] {++Portable presets++}: <br>Export/import YAML profiles for runtime behaviors, eliminating repetitive setup

??? tip ":material-numeric-6-circle-outline: ğ™¿ğš˜ğš›ğšğšŠğš‹ğš’ğš•ğš’ğšğš¢ ğšŠğš—ğš ğ™¿ğš›ğšŠğšŒğšğš’ğšŒğšŠğš•ğš’ğšğš¢"

    - [x] {++Decoupled pipeline++}: <br>Separation of data collection and visualization <br>

    - [x] {++Automatic device synchronization++}: <br>Maintains production-ready status by keeping model and data co-located <br>

    - [x] {++Dual-mode reporting with export flexibility++}: 
        - Measurement units mode vs. raw data mode
        - Multi-format export (`CSV`/`Excel`) for analysis integration

## â„¬. ğ¼ğ“ƒğ“ˆğ“‰ğ’¶ğ“ğ“ğ’¶ğ“‰ğ’¾ğ‘œğ“ƒ

???+ example "ğ™²ğš˜ğš–ğš™ğšŠğšğš’ğš‹ğš’ğš•ğš’ğšğš¢"

    <div class="grid cards" markdown>

    - :octicons-server-16:  __OS__: `windows` / `linux` / `macOS`
    - :material-language-python:  __Python__: >= 3.8
    - :simple-pytorch:  __Pytorch__: >= 1.7.0

    </div>

??? abstract "ğšƒğš‘ğš›ğš˜ğšğšğš‘ ğ™¿ğš¢ğšğš‘ğš˜ğš— ğ™¿ğšŠğšŒğš”ğšŠğšğš ğ™¼ğšŠğš—ğšŠğšğšğš›"

    > the most convenient way, suitable for installing the released **latest stable** version

    ```{ .bash .no-copy title="" linenums="0" hl_lines="2 5 8 11" } 
    # pip series
    pip/pipx/pipenv install torchmeter

    # Or via conda
    conda install torchmeter

    # Or via uv
    uv add torchmeter

    # Or via poetry
    poetry add torchmeter

    # Other managers' usage please refer to their own documentation
    ```

??? abstract "ğšƒğš‘ğš›ğš˜ğšğšğš‘ ğ™±ğš’ğš—ğšŠğš›ğš¢ ğ™³ğš’ğšœğšğš›ğš’ğš‹ğšğšğš’ğš˜ğš—"

    > Suitable for installing released historical versions

    1. Download `.whl` from [PyPI :material-link-variant:](https://pypi.org/project/torchmeter/#files) or [Github Releases :material-link-variant:](https://github.com/TorchMeter/torchmeter/releases).

    2. Install locally:

        ```bash title="" linenums="0"
        pip install torchmeter-x.x.x-py3-none-any.whl # (1)
        ```
        
        1.    ğŸ™‹â€â™‚ï¸ Replace `x.x.x` with actual version

??? abstract "ğšƒğš‘ğš›ğš˜ğšğšğš‘ ğš‚ğš˜ğšğš›ğšŒğš ğ™²ğš˜ğšğš"

    > Suitable for who want to try out the upcoming features (may has unknown bugs).

    ```bash  title="" linenums="0"
    git clone https://github.com/TorchMeter/torchmeter.git
    cd torchmeter

    # If you want to install the released stable version, use this: 
    git checkout vx.x.x # Stable (1)

    # If you want to try the latest development version(alpha/beta), use this:
    git checkout master  # Development version

    pip install .
    ```

    1.    ğŸ™‹â€â™‚ï¸ Don't forget to eplace `x.x.x` with actual version. You can check all available versions with `git tag -l`

## ğ’. ğ’¢ğ‘’ğ“‰ğ“‰ğ’¾ğ“ƒğ‘” ğ“ˆğ“‰ğ’¶ğ“‡ğ“‰ğ‘’ğ’¹

<!-- screenshot / gif -->

<script 
    src="https://asciinema.org/a/718060.js" 
    id="asciicast-718060"
    async="true"
    data-autoplay="true"
    data-preload="true"
    data-loop="true"
    data-cols="152"
    data-rows="28"
>
</script>

??? success ":material-numeric-1-circle-outline: ğ™³ğšğš•ğšğšğšŠğšğš ğš¢ğš˜ğšğš› ğš–ğš˜ğšğšğš• ğšğš˜ ğšğš˜ğš›ğšŒğš‘ğš–ğšğšğšğš›"

    ??? info "Implementation of ExampleNet"

        ```python
        import torch.nn as nn

        class ExampleNet(nn.Module):
            def __init__(self):
                super(ExampleNet, self).__init__()
                
                self.backbone = nn.Sequential(
                    self._nested_repeat_block(2),
                    self._nested_repeat_block(2)
                )

                self.gap = nn.AdaptiveAvgPool2d(1)

                self.classifier = nn.Linear(3, 2)
            
            def _inner_net(self):
                return nn.Sequential(
                    nn.Conv2d(10, 10, 1),
                    nn.BatchNorm2d(10),
                    nn.ReLU(),
                )

            def _nested_repeat_block(self, repeat:int=1):
                inners = [self._inner_net() for _ in range(repeat)]
                return nn.Sequential(
                    nn.Conv2d(3, 10, 3, stride=1, padding=1),
                    nn.BatchNorm2d(10),
                    nn.ReLU(),
                    *inners,
                    nn.Conv2d(10, 3, 1),
                    nn.BatchNorm2d(3),
                    nn.ReLU()
                )

            def forward(self, x):
                x = self.backbone(x)
                x = self.gap(x)
                x = x.squeeze(dim=(2,3))
                return self.classifier(x)
        ```

    ```python
    import torch.nn as nn
    from torchmeter import Meter
    from torch.cuda import is_available as is_cuda

    # 1ï¸âƒ£ Prepare your pytorch model, here is a simple examples
    underlying_model = ExampleNet() # (1)

    # Set an extra attribute to the model to show 
    # how torchmeter acts as a zero-intrusion proxy later
    underlying_model.example_attr = "ABC"

    # 2ï¸âƒ£ Wrap your model with torchmeter
    model = Meter(underlying_model)

    # 3ï¸âƒ£ Validate the zero-intrusion proxy

    # Get the model's attribute
    print(model.example_attr)

    # Get the model's method
    # `_inner_net` is a method defined in the ExampleNet
    print(hasattr(model, "_inner_net")) 

    # Move the model to other device (now on cpu)
    print(model)
    if is_cuda():
        model.to("cuda")
        print(model) # now on cuda
    ```

    1.    ğŸ™‹â€â™‚ï¸ see above for implementation of `ExampleNet`

??? success ":material-numeric-2-circle-outline: ğ™¶ğšğš ğš’ğš—ğšœğš’ğšğš‘ğšğšœ ğš’ğš—ğšğš˜ ğšğš‘ğš ğš–ğš˜ğšğšğš• ğšœğšğš›ğšğšŒğšğšğš›ğš"

    ```python
    from rich import print

    print(model.structure)
    ```

??? success ":material-numeric-3-circle-outline: ğš€ğšğšŠğš—ğšğš’ğšğš¢ ğš–ğš˜ğšğšğš• ğš™ğšğš›ğšğš˜ğš›ğš–ğšŠğš—ğšŒğš ğšğš›ğš˜ğš– ğšŸğšŠğš›ğš’ğš˜ğšğšœ ğšğš’ğš–ğšğš—ğšœğš’ğš˜ğš—ğšœ"

    ```python
    # Parameter Analysis
    # Suppose that the `backbone` part of ExampleNet is frozen
    _ = model.backbone.requires_grad_(False)
    print(model.param)
    tb, data = model.profile('param', no_tree=True)

    # Before measuring calculation you should first execute a feed-forward
    import torch
    input = torch.randn(1, 3, 32, 32)
    output = model(input) # (1)

    # Computational Profiling
    print(model.cal) # (2)
    tb, data = model.profile('cal', no_tree=True)

    # Memory Diagnostics
    print(model.mem) # (3)
    tb, data = model.profile('mem', no_tree=True)

    # Performance Benchmarking
    print(model.ittp) # (4)
    tb, data = model.profile('ittp', no_tree=True)

    # Overall Analytics
    print(model.overview())
    ```

    1.    ğŸ™‹â€â™‚ï¸ you do **not** need to concern about the device mismatch, just feed the model with the input.
    2.    ğŸ™‹â€â™‚ï¸ `cal` for calculation
    3.    ğŸ™‹â€â™‚ï¸ `mem` for memory
    4.    ğŸ™‹â€â™‚ï¸ `ittp` for inference time & throughput

??? success ":material-numeric-4-circle-outline: ğ™´ğš¡ğš™ğš˜ğš›ğš ğš›ğšğšœğšğš•ğšğšœ ğšğš˜ğš› ğšğšğš›ğšğš‘ğšğš› ğšŠğš—ğšŠğš•ğš¢ğšœğš’ğšœ"

    ```python
    # export to csv
    tb, data = model.profile('param', show=False, save_to="params.csv")

    # export to excel
    tb, data = model.profile('cal', show=False, save_to="../calculation.xlsx")
    ```

??? success ":material-numeric-5-circle-outline: ğ™°ğšğšŸğšŠğš—ğšŒğšğš ğšğšœğšŠğšğš"

    1. [Attributes/methods access of underlying model :material-link-variant:](demo.ipynb#b-zero-intrusion-proxy)
    2. [Automatic device synchronization :material-link-variant:](demo.ipynb#c-automatic-device-synchronization)
    3. [Smart module folding :material-link-variant:](demo.ipynb#d-model-structure-analysis)
    4. [Performance gallery :material-link-variant:](demo.ipynb#eb-overall-report)
    5. Customized visulization 
        - [for statistics overview :material-link-variant:](demo.ipynb#fa-customization-of-statistics-overview)
        - [for operation tree :material-link-variant:](demo.ipynb#fb-customization-of-rich-text-operation-tree)
        - [for tabular report :material-link-variant:](demo.ipynb#fc-customization-of-tabular-report)
    6. Best practice of programmable tabular report
        - [Real-time structure adjustment :material-link-variant:](demo.ipynb#fc3-customize-tabular-report-structure)   
        - [Real-time data analysis :material-link-variant:](demo.ipynb#fc34-add-a-new-column)
    7. [Instant export and postponed export :material-link-variant:](demo.ipynb#gb-postponed-export)
    8. [Centralized configuration management :material-link-variant:](demo.ipynb#h-centralized-configuration-management)
    9. [Submodule exploration :material-link-variant:](demo.ipynb#i4-submodule-explore)

## ğ’Ÿ. ğ’ğ‘œğ“ƒğ“‰ğ“‡ğ’¾ğ’·ğ“Šğ“‰ğ‘’

Thank you for wanting to make `TorchMeter` even better!

There are several ways to make a contribution:

- [:octicons-comment-discussion-16: **Asking questions** :material-link-variant:](contribute/discussions.md){ data-preview }
- [:octicons-issue-opened-16: **Reporting bugs** :material-link-variant:](contribute/issues.md){ data-preview }
- [:octicons-git-pull-request-16: **Contributing code** :material-link-variant:](contribute/prs.md){ data-preview }

Before jumping in, let's ensure smooth collaboration by reviewing our ğŸ“‹ [**contribution guidelines** :material-link-variant:](contribute/welcome_contributors.md){ data-preview } first. 

Thanks again !

## â„°. ğ’ğ‘œğ’¹ğ‘’ ğ‘œğ’» ğ’ğ‘œğ“ƒğ’¹ğ“Šğ’¸ğ“‰

> Refer to official [code-of-conduct file :material-link-variant:](https://github.com/TorchMeter/torchmeter/blob/master/CODE_OF_CONDUCT.md) for more details.

- `TorchMeter` is an open-source project built by developers worldwide. We're committed to fostering a **friendly, safe, and inclusive** environment for all participants. 

- The provisions stipulated in our [Code-of-Conduct file :material-link-variant:](https://github.com/TorchMeter/torchmeter/blob/master/CODE_OF_CONDUCT.md) are applicable to all community platforms, which include, but are not limited to, `GitHub` repositories, community forums, and similar ones. 

## â„±. ğ¿ğ’¾ğ’¸ğ‘’ğ“ƒğ“ˆğ‘’

- `TorchMeter` is released under the **AGPL-3.0 License**, see the [LICENSE :material-link-variant:](https://github.com/TorchMeter/torchmeter/blob/master/LICENSE) file for the full text. 
- Please carefully review the terms in the [LICENSE :material-link-variant:](https://github.com/TorchMeter/torchmeter/blob/master/LICENSE) file before using or distributing `TorchMeter`. 
- Ensure compliance with the licensing conditions, especially when integrating this project into larger systems or proprietary software.